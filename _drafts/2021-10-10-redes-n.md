---
layout: post
title: "Rendimentos decrescentes em NLP"
comments: true
mathjax: true
description: "A solução de código"
keywords: "LSTM, NLP, Deep Learning"
---

Em Economia, a lei dos [rendimentos descrescentes](https://en.wikipedia.org/wiki/Diminishing_returns) fala sobre a relação entre trabalho e produção, que tende a piorar à medida em que se investe mais trabalho. De forma mais precisa, dado: $$ Entrada = E $$, $$ Saida = S $$ e $$ S = f(E) $$. A teoria diz que: $$ 2 \times f(E) > f(2 \times E) $$. 

Talvez não por esse nome, mas essa dinâmica de rendimentos decrescentes, é muito familar às pessoas que lidam com modelagem. Aumentar o desempenho de um modelo, se torna mais complicado à medida em que se avança, como podemos ver soluções desenvolvidas para cenários competitivos como o [desafio Netflix](https://analyticsindiamag.com/how-useful-was-the-netflix-prize-really/).

Em resumo: melhorar os últimos 5% de um modelo é muito mais díficil que os primeiros 10%. Em um contexto de negócios, é muito importante ter em mente essa dinâmica, pois há um momento em que não faz mais sentido investir na modelagem.

Pensando mais especificamente, em problemas de NLP: quando vale a pena pular de uma solução mais simples, baseada em *bag of words* por exemplo, para algo mais sofisticado envolvendo *embeddings* e redes neurais? Aliás, realmente vale a pena fazer esse pulo?

Pensando nessa questão, vou explorar um pouco esse problema trabalhando com o clássico problema de classificação de resenhas, usando o [corpus do Skoob]((/2019/07/27/corpus-skoob.html)) que discuti em um post anterior.

## Neural NLP 

A área de NLP passou por uma [revolução](https://jmlr.csail.mit.edu/papers/volume12/collobert11a/collobert11a.pdf), com o uso de *word embeddings* e redes neurais convolucionais/recorrentes. São conceitos relativamente independentes – e que já existiam há tempos – mas que algumas evoluções tornaram seu uso muito interessante para problemas de NLP.

Um dos maiores exemplos de sucesso dessa nova abordagem, foram os sistemas de tradução automática. Deixaram de ser sistemas complexos e altamente especializados, para modelos de linguagem condicionais [Seq2seq](https://en.wikipedia.org/wiki/Seq2seq). 

Um modelo Seq2seq propõe uma solução mais universal e simples para o problema. Adaptar um sistema Seq2seq para trabalhar em traduções para o português, é menos complexo que fazer o mesmo para um sistema especialista. 

Quando os avanços de NLP dependiam de recursos sofisticados, como corpus anotados por linguistas e antologias, era muito díficil adaptar soluções de outros idiomas para língua portuguesa. Nesse contexto, são comuns soluções muito baseadas em contagem de palavras, que se furtam de usar conceitos mais complexos (*e.g.* ontologias, árvores de dependência, gramáticas).

Nesse novo cenário – de modelos poderosos mais genéricos – normalmente há duas opções de atuação em um problema de NLP:

* Soluções baseadas em *[bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model)*, que a despeito das claras limitações, são muito simples de implementar e acabam atendendo vários casos de uso.

* Soluções baseadas em redes neurais, que lida melhor com muito das limitações dos modelos *bag of words* e são mais próximas do estado da arte, mas demandam mais esforço de desenvolvimento e poder computacional.

Há um degrau claro de complexidade entre as as duas abordagens, mas é dificil estimar o custo/benefício em termos de desempenho. Para elucidar um pouco essa questão, minha proposta é abordar um problema de classificação a partir das duas abordagens.

## O problema ~~manjado~~ de resenhas

Anos atrás, eu fiz um script para extrair [resenhas do Skoob](/2019/07/27/corpus-skoob.html) feitas pelos usuários, que não usei para nada até esse momento. 

Sendo um corpus de resenhas, o leitor já deve suspeitar do plano: fazer um classificador de notas a partir do texto das resenhas, o clássico problema de análise de sentimentos[^1].

[^1]: não gosto do termo "análise de sentimentos", acho o termo prensioso demais e o conceito mal definido. Por exemplo, é válido chamar um classificador de estrelas como de sentimentos?

Além de escrever a resenha, o usuário do Skoob tem a opção de atribuir estrelas ao livro. Como de costume, as estrelas variam no intervalo $$  [1,5] $$, mas optei por trabalhar apenas com o subconjunto $$ \{1, 3, 5\} $$ para fazer o classificador.

Optei por essa estratégia, porque essa gradação de notas subjetivas é uma questão díficil de se trabalhar, tanto que YouTube e Netflix optaram por migrar de um sistema de estrelas para notas binárias (curti e não curti). Inclusive, pretendia usar apenas o valores extremos $$ \{1,5\} $$, entretanto as classes ficariam muito desbalanceadas. 

Há muitos questionamentos possíveis para esse meu recorte do *corpus*, optei pela redução para simplificar a definição do problema. Há detalhes conceituais em lidar com gradações, que merecem uma análise apartada. Por exemplo, será que existe um critério comum entre pessoas para distinguir entre 4 e 5 estrelas?

Como a ideia é mais comparar abordagens de modelagem e não resolver um problema real, acredito que esse recorte não seja uma questão crucial para a discussão. Definido o critério de seleção do corpus, o dataset final ficou com um total **828.118** resenhas: **23.893** com 1 estrela,  **174.836** com 3 estrelas e **629.389** com 5 estrelas.

## Comparando as estratégias

Definido o problema de classificação, a ideia é comparar duas abordagens, uma baseada em redes neurais e *word-embeddings* e outra utilizando classificadores mais simples e representação *bag of words*.

Não será uma comparação completa entre as soluções, pois não haverá o ajuste fino dos classificadores e preparação de dados. Uma comparação mais exaustiva das abordagens seria muito bom, mas entendo que essa comparação *baseline* já mostra algumas coisas interessantes.

Sendo um problema multi-classe e desbalanceado, acho interessante trabalhar com matriz de confusão, além da acurácia simples. Usando a matriz de confusão, o leitor tem uma visão global dos erros e calcular métricas mais sofisticadas.

Sendo um conjunto de dados grande, vou separá-lo em validação com 90% (**745.307**  amostras) para treino e os 10% restantes (**82.811** amostras) para validação. 

## Montando o baseline

Para começar um experimento de classificação em NLP, acredito que o caminho mais clássico possível é usar um classificador Naive Bayes. É um classificador simples, que separa as classes baseada na diferença das distribuições de palavras que compõe os textos de cada classe.

Uma limitação desse classificador – que está em seu próprio nome – é a premissa "ingênua" de que as dimensões são independentes entre si. Ou seja, que as ocorrências das palavras dentro de um texto são independentes entre si. Outra limitação, mas essa proveniente da representação *bag of words*, é desconsiderar a ordem das palavras.

A despeita dessas limitações, é um classificador simples e [bem adaptado](https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf) a problemas que lidam com textos. Abaixo, os primeiros resultados do experimento:

<figure>
  <img src="{{site.url}}/assets/images/ml-skoob/MultinomialNB.svg"/>
  <figcaption>Figura 1 – Resultados Naive Bayes </figcaption>
</figure>

Os resultados foram obtidos da forma mais básica possível, para fazer a transformação dos textos usei o [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) do scikit-learn:

```python
vectorizer = CountVectorizer(stop_words=stopwords.words('portuguese'))
```

A lista de stopwords eu usei a presente no [repositório do NLTK](https://gist.github.com/alopes/5358189). Além das stopwods, experimentei usar o [RSLP](https://www.nltk.org/_modules/nltk/stem/rslp.html), um algoritmo de stemming para língua portuguesa. Nenhum desses pré-processamento tiveram impacto no classificador. 

Infelizmente, não consegui usar [n-gram](https://en.wikipedia.org/wiki/N-gram) maior que 2, devido a falta de memória no computador. De qualquer forma, os melhores resultados foram obtidos sem o uso de n-grams.

Em sua versão multinomial, não há muitos hiper-parâmetros no classificador [Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html). Há a possibilidade de ignorar a probabilidade *a priori*, mas impactou negativamente o desempenho ao distinguir as resenhas neutras e negativas.

## Subindo o baseline com SVM e TF-IDF

Um outro classificador – bastante utilizado em problemas de NLP – é o [SVM linear](https://link.springer.com/chapter/10.1007%2FBFb0026683). 

A representação *bag of words* geram vetores de alta dimensão, mas muito esparsos. A alta dimensão desses vetores facilitam com que sejam separáveis linearmente, entretanto pode ser díficil ajustar um modelo com dados esparsos. O treinamento do SVM – que é feito via a otimização distância entre margens – é ideal para esse tipo de problema.

Uma outra vantagem desse modelo, é ser possível usar [tf-idf](https://en.wikipedia.org/wiki/Tf–idf) para destacar as palavras mais importantes do corpus ao representar um texto. É uma representação muito usada em problemas de [information retrieval](https://en.wikipedia.org/wiki/Information_retrieval), mas que também pode ser útil em classificação.

Usando esse combo, já conseguimos um melhor desempenho de classificação:

